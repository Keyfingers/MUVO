"""
å¿«é€Ÿå¼€å§‹è®­ç»ƒè„šæœ¬ - ç®€åŒ–ç‰ˆ
ç”¨äºå¿«é€Ÿæµ‹è¯•è®­ç»ƒæµç¨‹
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from pathlib import Path
import time
from tqdm import tqdm
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# å¯¼å…¥æ•°æ®åŠ è½½å™¨
from muvo.dataset.anovox_dataset import create_anovox_dataloader


class SimpleAnomalyDetector(nn.Module):
    """
    ç®€åŒ–çš„å¼‚å¸¸æ£€æµ‹æ¨¡å‹ - ç”¨äºå¿«é€Ÿæµ‹è¯•
    """
    def __init__(self):
        super().__init__()
        
        # å›¾åƒç‰¹å¾æå–ï¼ˆç®€åŒ–ï¼‰
        self.image_conv = nn.Sequential(
            nn.Conv2d(3, 32, 7, stride=2, padding=3),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((8, 8))
        )
        
        # ç‚¹äº‘ç‰¹å¾æå–ï¼ˆç®€åŒ– - ä½¿ç”¨PointNeté£æ ¼ï¼‰
        self.point_mlp = nn.Sequential(
            nn.Linear(4, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU()
        )
        
        # èåˆå±‚
        self.fusion = nn.Sequential(
            nn.Linear(64 * 64 + 128, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )
    
    def forward(self, batch):
        # å¤„ç†å›¾åƒ
        img = batch['image']  # [B, 3, H, W]
        img_feat = self.image_conv(img)  # [B, 64, 8, 8]
        img_feat = img_feat.view(img_feat.size(0), -1)  # [B, 64*64]
        
        # å¤„ç†ç‚¹äº‘ï¼ˆç®€åŒ–ï¼šå–æœ€å¤§æ± åŒ–ï¼‰
        points = batch['points']  # [B, N, 4]
        # é™åˆ¶ç‚¹æ•°ä»¥èŠ‚çœæ˜¾å­˜
        if points.size(1) > 10000:
            indices = torch.randperm(points.size(1))[:10000]
            points = points[:, indices, :]
        
        point_feat = self.point_mlp(points)  # [B, N, 128]
        point_feat = torch.max(point_feat, dim=1)[0]  # [B, 128] å…¨å±€æœ€å¤§æ± åŒ–
        
        # èåˆ
        combined = torch.cat([img_feat, point_feat], dim=1)  # [B, 64*64+128]
        anomaly_score = self.fusion(combined)  # [B, 1]
        
        return {
            'anomaly_score': anomaly_score,
            'image_features': img_feat,
            'point_features': point_feat
        }


def train_epoch(model, dataloader, optimizer, criterion, device, epoch):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    total_anomaly = 0
    
    pbar = tqdm(dataloader, desc=f'Epoch {epoch}')
    for batch_idx, batch in enumerate(pbar):
        # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
        batch['image'] = batch['image'].to(device)
        batch['points'] = batch['points'].to(device)
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = model(batch)
        
        # è®¡ç®—æŸå¤±ï¼ˆè‡ªç›‘ç£ï¼šå‡è®¾å¤§éƒ¨åˆ†æ˜¯æ­£å¸¸çš„ï¼‰
        anomaly_score = outputs['anomaly_score']
        # ç®€å•æŸå¤±ï¼šé¼“åŠ±åˆ†æ•°æ¥è¿‘0ï¼ˆæ­£å¸¸ï¼‰+ ä¸€äº›æ­£åˆ™åŒ–
        loss = torch.mean(anomaly_score) + 0.1 * torch.std(anomaly_score)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        # ç»Ÿè®¡
        total_loss += loss.item()
        total_anomaly += anomaly_score.mean().item()
        
        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix({
            'loss': f'{loss.item():.4f}',
            'anomaly': f'{anomaly_score.mean().item():.4f}'
        })
        
        # å®Œæ•´è®­ç»ƒï¼šä¸é™åˆ¶æ­¥æ•°
        # if batch_idx >= 100:
        #     break
    
    avg_loss = total_loss / len(dataloader)
    avg_anomaly = total_anomaly / len(dataloader)
    
    return avg_loss, avg_anomaly


def visualize_results(train_losses, train_anomalies, save_dir='visualizations'):
    """å¯è§†åŒ–è®­ç»ƒç»“æœ"""
    save_dir = Path(save_dir)
    save_dir.mkdir(exist_ok=True)
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # æŸå¤±æ›²çº¿
    ax1.plot(train_losses, 'b-', linewidth=2, marker='o')
    ax1.set_xlabel('Epoch', fontsize=12)
    ax1.set_ylabel('Loss', fontsize=12)
    ax1.set_title('Training Loss', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    # å¼‚å¸¸åˆ†æ•°æ›²çº¿
    ax2.plot(train_anomalies, 'r-', linewidth=2, marker='s')
    ax2.set_xlabel('Epoch', fontsize=12)
    ax2.set_ylabel('Anomaly Score', fontsize=12)
    ax2.set_title('Average Anomaly Score', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    save_path = save_dir / 'quick_training_results.png'
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"âœ… å¯è§†åŒ–ä¿å­˜è‡³: {save_path}")
    plt.close()


def main():
    print("=" * 60)
    print("ğŸš€ å¿«é€Ÿè®­ç»ƒæµ‹è¯•å¼€å§‹")
    print("=" * 60)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print(f"\nğŸ“ åŠ è½½æ•°æ®...")
    train_loader = create_anovox_dataloader(
        data_root='/root/autodl-tmp/datasets/AnoVox/AnoVox_Dynamic_Mono_Town07',
        split='train',
        batch_size=2,  # å°batch size
        num_workers=2,
        shuffle=True
    )
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(train_loader.dataset)} æ ·æœ¬")
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸ åˆå§‹åŒ–æ¨¡å‹...")
    model = SimpleAnomalyDetector().to(device)
    
    # ç»Ÿè®¡å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    print(f"âœ… æ¨¡å‹å‚æ•°: {total_params:,}")
    
    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.BCELoss()
    
    # è®­ç»ƒé…ç½®
    num_epochs = 50  # å®Œæ•´è®­ç»ƒ
    
    # è®­ç»ƒå¾ªç¯
    print(f"\nğŸ“ å¼€å§‹å®Œæ•´è®­ç»ƒ...")
    print(f"ğŸ’¡ è®­ç»ƒ{num_epochs}ä¸ªepochsï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®\n")
    train_losses = []
    train_anomalies = []
    
    start_time = time.time()
    
    for epoch in range(1, num_epochs + 1):
        loss, anomaly = train_epoch(model, train_loader, optimizer, criterion, device, epoch)
        train_losses.append(loss)
        train_anomalies.append(anomaly)
        
        print(f"\nğŸ“Š Epoch {epoch} Summary:")
        print(f"   Loss: {loss:.4f}")
        print(f"   Anomaly Score: {anomaly:.4f}")
        print(f"   Time: {time.time() - start_time:.1f}s\n")
    
    # ä¿å­˜æ¨¡å‹
    model_path = Path('checkpoints') / 'simple_anomaly_detector.pth'
    model_path.parent.mkdir(exist_ok=True)
    torch.save(model.state_dict(), model_path)
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    # å¯è§†åŒ–ç»“æœ
    print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–...")
    visualize_results(train_losses, train_anomalies)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ å¿«é€Ÿè®­ç»ƒæµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
    print(f"\nğŸ“ˆ è®­ç»ƒæ€»ç»“:")
    print(f"   - æ€»æ—¶é—´: {time.time() - start_time:.1f}ç§’")
    print(f"   - åˆå§‹æŸå¤±: {train_losses[0]:.4f}")
    print(f"   - æœ€ç»ˆæŸå¤±: {train_losses[-1]:.4f}")
    print(f"   - æ”¹å–„: {((train_losses[0] - train_losses[-1]) / train_losses[0] * 100):.1f}%")
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"   - æ¨¡å‹: checkpoints/simple_anomaly_detector.pth")
    print(f"   - å¯è§†åŒ–: visualizations/quick_training_results.png")


if __name__ == '__main__':
    main()

