"""
æµ‹è¯•ç²¾ç¡®ä½“ç´ -ç‚¹æ˜ å°„V2ï¼ˆä½¿ç”¨çœŸå®ä½“ç´ æ•°æ®ï¼‰
"""

import sys
import torch
import numpy as np
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from muvo.config import _C
from muvo.dataset.anovox_dataset import AnoVoxDataset, collate_fn
from torch.utils.data import DataLoader
from precise_voxel_mapping_v2 import create_precise_point_labels_from_voxels


def main():
    print("=" * 80)
    print("ğŸ”¬ æµ‹è¯•ç²¾ç¡®ä½“ç´ -ç‚¹æ˜ å°„ V2")
    print("=" * 80)
    
    cfg = _C.clone()
    
    # åˆ›å»ºæ•°æ®é›†ï¼ˆåŠ è½½ä½“ç´ æ•°æ®ï¼‰
    dataset = AnoVoxDataset(
        data_root='/root/autodl-tmp/datasets/AnoVox/AnoVox_Dynamic_Mono_Town07',
        split='train',
        load_anomaly_labels=True,
        load_voxel=True  # å…³é”®ï¼šåŠ è½½ä½“ç´ æ•°æ®
    )
    
    print(f"âœ… æ•°æ®é›†: {len(dataset)} æ ·æœ¬\n")
    
    # åˆ›å»ºDataLoader
    dataloader = DataLoader(
        dataset,
        batch_size=4,
        shuffle=False,
        collate_fn=collate_fn,
        num_workers=0
    )
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  è®¾å¤‡: {device}\n")
    
    # æµ‹è¯•å‡ ä¸ªæ‰¹æ¬¡
    total_samples = 0
    total_points = 0
    total_anomaly_points = 0
    anomaly_samples = 0
    
    for batch_idx, batch in enumerate(dataloader):
        if batch_idx >= 5:  # åªæµ‹è¯•å‰5ä¸ªæ‰¹æ¬¡
            break
        
        print(f"\n{'='*80}")
        print(f"æ‰¹æ¬¡ {batch_idx + 1}")
        print(f"{'='*80}")
        
        # å‡†å¤‡æ•°æ®
        points = batch['points'].to(device)
        B, N, _ = points.shape
        
        print(f"ç‚¹äº‘å½¢çŠ¶: {points.shape}")
        
        # è·å–ä½“ç´ æ•°æ®
        voxel_data_list = batch.get('voxel', [])
        print(f"ä½“ç´ æ•°æ®: {len(voxel_data_list)} ä¸ªæ ·æœ¬")
        
        for i, voxel_data in enumerate(voxel_data_list):
            if voxel_data is not None and len(voxel_data) > 0:
                # è½¬æ¢ä¸ºnumpy
                if isinstance(voxel_data, torch.Tensor):
                    voxel_np = voxel_data.cpu().numpy()
                else:
                    voxel_np = voxel_data
                
                print(f"  æ ·æœ¬ {i}: voxelå½¢çŠ¶ = {voxel_np.shape}")
                
                # ç»Ÿè®¡è¯­ä¹‰IDåˆ†å¸ƒ
                if voxel_np.shape[1] >= 4:
                    semantic_ids = voxel_np[:, 3]
                    unique_ids, counts = np.unique(semantic_ids, return_counts=True)
                    print(f"    è¯­ä¹‰ID: {dict(zip(unique_ids.astype(int), counts))}")
        
        # è½¬æ¢voxelæ•°æ®ä¸ºnumpyåˆ—è¡¨
        voxel_data_list_np = []
        for voxel_tensor in voxel_data_list:
            if voxel_tensor is None or len(voxel_tensor) == 0:
                voxel_data_list_np.append(np.array([]).reshape(0, 4))
            elif isinstance(voxel_tensor, torch.Tensor):
                voxel_data_list_np.append(voxel_tensor.cpu().numpy())
            else:
                voxel_data_list_np.append(voxel_tensor)
        
        # è·å–å¼‚å¸¸æ ‡ç­¾
        anomaly_labels = batch.get('anomaly_label', [{}] * B)
        
        print(f"\nå¼‚å¸¸æ ‡ç­¾:")
        for i, label in enumerate(anomaly_labels):
            is_alive = label.get('anomaly_is_alive', 'N/A')
            print(f"  æ ·æœ¬ {i}: anomaly_is_alive = {is_alive}")
        
        # ç”Ÿæˆç²¾ç¡®æ ‡ç­¾
        print(f"\nğŸ¯ ç”Ÿæˆç²¾ç¡®æ ‡ç­¾...")
        labels = create_precise_point_labels_from_voxels(
            points_batch=points,
            voxel_data_list=voxel_data_list_np,
            anomaly_labels_batch=anomaly_labels,
            cfg=cfg,
            device=device
        )
        
        # ç»Ÿè®¡
        for i in range(B):
            labels_i = labels[i].cpu().numpy()
            anomaly_count = (labels_i == 1.0).sum()
            
            total_samples += 1
            total_points += len(labels_i)
            total_anomaly_points += anomaly_count
            
            if anomaly_count > 0:
                anomaly_samples += 1
                print(f"âœ… æ ·æœ¬ {i}: {anomaly_count}/{len(labels_i)} ({100*anomaly_count/len(labels_i):.2f}%) å¼‚å¸¸ç‚¹")
            else:
                print(f"âšª æ ·æœ¬ {i}: {anomaly_count}/{len(labels_i)} (0.00%) å¼‚å¸¸ç‚¹")
    
    # æ€»ä½“ç»Ÿè®¡
    print(f"\n{'='*80}")
    print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡")
    print(f"{'='*80}")
    print(f"æ€»æ ·æœ¬æ•°: {total_samples}")
    print(f"æœ‰å¼‚å¸¸çš„æ ·æœ¬: {anomaly_samples} ({100*anomaly_samples/total_samples:.1f}%)")
    print(f"æ€»ç‚¹æ•°: {total_points:,}")
    print(f"å¼‚å¸¸ç‚¹: {total_anomaly_points:,} ({100*total_anomaly_points/total_points:.2f}%)")
    print(f"æ­£å¸¸ç‚¹: {total_points - total_anomaly_points:,} ({100*(total_points - total_anomaly_points)/total_points:.2f}%)")
    
    if total_anomaly_points > 0:
        pos_weight = (total_points - total_anomaly_points) / total_anomaly_points
        print(f"\nğŸ’¡ å»ºè®®çš„ pos_weight: {pos_weight:.1f}")
        print(f"\nâœ… ç²¾ç¡®æ˜ å°„éªŒè¯æˆåŠŸï¼å¯ä»¥ç”¨äºè®­ç»ƒï¼")
    else:
        print(f"\nâš ï¸ è­¦å‘Šï¼šæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•å¼‚å¸¸ç‚¹ï¼")
        print(f"å¯èƒ½çš„åŸå› ï¼š")
        print(f"1. Zè½´åŸç‚¹å‚æ•°éœ€è¦è°ƒæ•´ï¼ˆå½“å‰=-2.0mï¼‰")
        print(f"2. å¼‚å¸¸è¯­ä¹‰IDé›†åˆä¸å®Œæ•´")
        print(f"3. åæ ‡ç³»å˜æ¢å‚æ•°ä¸æ­£ç¡®")


if __name__ == '__main__':
    main()

