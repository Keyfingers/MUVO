"""
åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹
æµ‹è¯•é›†ä½¿ç”¨AnoVox_Dynamic_Mono_Town07çš„ç‹¬ç«‹å­é›†
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from pathlib import Path
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from tqdm import tqdm

import sys
sys.path.insert(0, str(Path(__file__).parent))

from muvo.dataset.anovox_dataset import AnoVoxDataset, collate_fn
from muvo.config import _C

# å¯¼å…¥åœºæ™¯çº§æ¨¡å‹
import importlib.util
spec = importlib.util.spec_from_file_location("train_scene", "train_scene_level_detection.py")
train_scene = importlib.util.module_from_spec(spec)
spec.loader.exec_module(train_scene)
SceneLevelAnomalyDetector = train_scene.SceneLevelAnomalyDetector

def evaluate_model(model, test_loader, device):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    model.eval()
    
    all_preds = []
    all_labels = []
    all_probs = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Testing"):
            # æ•°æ®ç§»åˆ°GPU
            batch['image'] = batch['image'].to(device)
            batch['points'] = batch['points'].to(device)
            
            # å‰å‘ä¼ æ’­
            outputs = model(batch)
            logits = outputs['scene_logit']
            probs = torch.sigmoid(logits).squeeze()
            preds = (probs > 0.5).float()
            
            # æå–æ ‡ç­¾
            labels = []
            for anomaly_dict in batch['anomaly_label']:
                is_alive = anomaly_dict.get('anomaly_is_alive', 'False')
                label = 1.0 if (isinstance(is_alive, str) and is_alive.lower() == 'true') else 0.0
                labels.append(label)
            labels = torch.tensor(labels, device=device)
            
            # æ”¶é›†ç»“æœ
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    all_probs = np.array(all_probs)
    
    # è®¡ç®—æŒ‡æ ‡
    accuracy = accuracy_score(all_labels, all_preds) * 100
    precision = precision_score(all_labels, all_preds, zero_division=0) * 100
    recall = recall_score(all_labels, all_preds, zero_division=0) * 100
    f1 = f1_score(all_labels, all_preds, zero_division=0) * 100
    
    # è®¡ç®—AUROCï¼ˆå¦‚æœæœ‰ä¸¤ä¸ªç±»åˆ«ï¼‰
    if len(np.unique(all_labels)) > 1:
        auroc = roc_auc_score(all_labels, all_probs) * 100
    else:
        auroc = None
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)
    if cm.size == 4:
        tn, fp, fn, tp = cm.ravel()
    elif cm.size == 1:
        # åªæœ‰ä¸€ä¸ªç±»åˆ«çš„æƒ…å†µ
        if all_labels[0] == 1:
            tp = int(cm[0, 0])
            tn, fp, fn = 0, 0, 0
        else:
            tn = int(cm[0, 0])
            tp, fp, fn = 0, 0, 0
    else:
        tn, fp, fn, tp = 0, 0, 0, 0
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'auroc': auroc,
        'confusion_matrix': {
            'TP': int(tp),
            'TN': int(tn),
            'FP': int(fp),
            'FN': int(fn)
        },
        'predictions': all_preds,
        'labels': all_labels,
        'probabilities': all_probs
    }

def main():
    print("=" * 80)
    print("ğŸ§ª æµ‹è¯•é›†è¯„ä¼°")
    print("=" * 80)
    
    # è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æµ‹è¯•æ•°æ®é›†
    # ä½¿ç”¨Dynamic_Mono_Town07çš„ç‹¬ç«‹æµ‹è¯•é›†
    print("\nğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®é›†...")
    test_dataset = AnoVoxDataset(
        data_root='/root/autodl-tmp/datasets/AnoVox',
        split='test',
        dataset_types=['Dynamic_Mono_Town07'],  # çº¯å¼‚å¸¸æµ‹è¯•é›†
        load_anomaly_labels=True,
        load_voxel=False
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=8,
        shuffle=False,
        num_workers=4,
        pin_memory=True,
        collate_fn=collate_fn  # ä½¿ç”¨è‡ªå®šä¹‰collateå‡½æ•°
    )
    
    print(f"âœ… æµ‹è¯•é›†å¤§å°: {len(test_dataset)} æ ·æœ¬")
    print(f"ğŸ“¦ æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}")
    
    # åŠ è½½æ¨¡å‹
    print("\nğŸ¤– åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
    cfg = _C.clone()
    model = SceneLevelAnomalyDetector(cfg).to(device)
    
    checkpoint_path = 'checkpoints/scene_level_best.pth'
    if not Path(checkpoint_path).exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        return
    
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {checkpoint_path}")
    print(f"   è®­ç»ƒEpoch: {checkpoint.get('epoch', 'N/A')}")
    best_recall = checkpoint.get('best_recall', None)
    if best_recall is not None:
        print(f"   è®­ç»ƒRecall: {best_recall:.2f}%")
    
    # è¯„ä¼°
    print("\nğŸ”¬ å¼€å§‹æµ‹è¯•...")
    results = evaluate_model(model, test_loader, device)
    
    # æ‰“å°ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š æµ‹è¯•é›†è¯„ä¼°ç»“æœ")
    print("=" * 80)
    print(f"\nğŸ¯ æ ¸å¿ƒæŒ‡æ ‡:")
    print(f"   Accuracy:  {results['accuracy']:.2f}%")
    print(f"   Precision: {results['precision']:.2f}%")
    print(f"   Recall:    {results['recall']:.2f}%")
    print(f"   F1-Score:  {results['f1']:.2f}%")
    if results['auroc'] is not None:
        print(f"   AUROC:     {results['auroc']:.2f}%")
    
    print(f"\nğŸ¯ æ··æ·†çŸ©é˜µ:")
    cm = results['confusion_matrix']
    print(f"   True Positive (TP):  {cm['TP']}")
    print(f"   True Negative (TN):  {cm['TN']}")
    print(f"   False Positive (FP): {cm['FP']}")
    print(f"   False Negative (FN): {cm['FN']}")
    
    # è®¡ç®—è¯¯æŠ¥ç‡å’Œæ¼æ£€ç‡
    fpr = cm['FP'] / (cm['FP'] + cm['TN']) * 100 if (cm['FP'] + cm['TN']) > 0 else 0
    fnr = cm['FN'] / (cm['FN'] + cm['TP']) * 100 if (cm['FN'] + cm['TP']) > 0 else 0
    
    print(f"\nâš ï¸ é”™è¯¯åˆ†æ:")
    print(f"   False Positive Rate (FPR): {fpr:.2f}%")
    print(f"   False Negative Rate (FNR): {fnr:.2f}%")
    
    # ä¿å­˜ç»“æœ
    output_dir = Path('test_results')
    output_dir.mkdir(exist_ok=True)
    
    np.savez(
        output_dir / 'test_results.npz',
        predictions=results['predictions'],
        labels=results['labels'],
        probabilities=results['probabilities'],
        metrics={
            'accuracy': results['accuracy'],
            'precision': results['precision'],
            'recall': results['recall'],
            'f1': results['f1'],
            'auroc': results['auroc']
        }
    )
    
    # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
    with open(output_dir / 'test_report.txt', 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("æµ‹è¯•é›†è¯„ä¼°æŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"æµ‹è¯•é›†å¤§å°: {len(test_dataset)} æ ·æœ¬\n\n")
        f.write(f"æ ¸å¿ƒæŒ‡æ ‡:\n")
        f.write(f"  Accuracy:  {results['accuracy']:.2f}%\n")
        f.write(f"  Precision: {results['precision']:.2f}%\n")
        f.write(f"  Recall:    {results['recall']:.2f}%\n")
        f.write(f"  F1-Score:  {results['f1']:.2f}%\n")
        if results['auroc'] is not None:
            f.write(f"  AUROC:     {results['auroc']:.2f}%\n")
        f.write(f"\næ··æ·†çŸ©é˜µ:\n")
        f.write(f"  TP: {cm['TP']}, TN: {cm['TN']}, FP: {cm['FP']}, FN: {cm['FN']}\n")
        f.write(f"\né”™è¯¯åˆ†æ:\n")
        f.write(f"  FPR: {fpr:.2f}%\n")
        f.write(f"  FNR: {fnr:.2f}%\n")
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_dir}/")
    print("=" * 80)

if __name__ == "__main__":
    main()

