"""
AnoVoxå¼‚å¸¸æ£€æµ‹è®­ç»ƒè„šæœ¬
Training Script for AnoVox Anomaly Detection

ä½¿ç”¨æ–¹æ³•:
python train_anovox.py --config muvo/configs/anovox_training.yml
"""

import os
import sys
import argparse
import torch
import torch.nn as nn
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor
from pytorch_lightning.loggers import TensorBoardLogger
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from muvo.config import get_cfg
from muvo.models.mile_anomaly import MileAnomalyDetection
from muvo.dataset.anovox_dataset import create_anovox_dataloader


class AnomalyDetectionModule(pl.LightningModule):
    """
    PyTorch Lightningæ¨¡å— - ç”¨äºè®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹
    """
    
    def __init__(self, cfg):
        super().__init__()
        self.cfg = cfg
        self.model = MileAnomalyDetection(cfg)
        
        # æŸå¤±å‡½æ•°
        self.criterion = nn.BCEWithLogitsLoss()
        
        # ä¿å­˜è¶…å‚æ•°
        self.save_hyperparameters()
        
        # ç”¨äºè®°å½•è®­ç»ƒæŒ‡æ ‡
        self.training_step_outputs = []
        self.validation_step_outputs = []
        
        print("=" * 60)
        print("ğŸš€ æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        self._print_model_info()
        print("=" * 60)
    
    def _print_model_info(self):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        frozen_params = total_params - trainable_params
        
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
        print(f"  - æ€»å‚æ•°: {total_params:,}")
        print(f"  - å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({100*trainable_params/total_params:.1f}%)")
        print(f"  - å†»ç»“å‚æ•°: {frozen_params:,} ({100*frozen_params/total_params:.1f}%)")
        print(f"\nğŸ¯ è®­ç»ƒé…ç½®:")
        print(f"  - Batch Size: {self.cfg.BATCHSIZE}")
        print(f"  - Learning Rate: {self.cfg.OPTIMIZER.LR}")
        print(f"  - Max Epochs: {self.cfg.OPTIMIZER.EPOCHS}")
    
    def forward(self, batch):
        """å‰å‘ä¼ æ’­"""
        return self.model(batch)
    
    def training_step(self, batch, batch_idx):
        """è®­ç»ƒæ­¥éª¤"""
        try:
            # å‰å‘ä¼ æ’­
            outputs = self(batch)
            
            # è®¡ç®—æŸå¤±ï¼ˆå‡è®¾æœ‰å¼‚å¸¸æ ‡ç­¾ï¼‰
            if 'anomaly_label' in batch:
                # å¦‚æœæœ‰çœŸå€¼æ ‡ç­¾
                anomaly_scores = outputs['anomaly_scores']
                labels = batch['anomaly_label']
                
                # è°ƒæ•´æ ‡ç­¾å½¢çŠ¶ä»¥åŒ¹é…é¢„æµ‹
                if isinstance(labels, dict):
                    # å¦‚æœæ ‡ç­¾æ˜¯å­—å…¸æ ¼å¼ï¼Œæå–å®é™…æ ‡ç­¾
                    labels = torch.zeros_like(anomaly_scores)
                
                loss = self.criterion(anomaly_scores, labels.float())
            else:
                # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œä½¿ç”¨è‡ªç›‘ç£æŸå¤±ï¼ˆç®€åŒ–ç‰ˆï¼‰
                # è¿™é‡Œå‡è®¾å¤§éƒ¨åˆ†æ•°æ®æ˜¯æ­£å¸¸çš„
                anomaly_scores = outputs['anomaly_scores']
                # ç®€å•çš„æŸå¤±ï¼šé¼“åŠ±åˆ†æ•°æ¥è¿‘0ï¼ˆæ­£å¸¸ï¼‰
                loss = torch.mean(anomaly_scores)
            
            # è®°å½•æŸå¤±
            self.log('train_loss', loss, prog_bar=True, logger=True, on_step=True, on_epoch=True)
            
            # è®°å½•å…¶ä»–æŒ‡æ ‡
            anomaly_prob = outputs['anomaly_probability'].mean()
            self.log('train_anomaly_prob', anomaly_prob, prog_bar=False, logger=True)
            
            # ä¿å­˜è¾“å‡ºç”¨äºepochç»“æŸæ—¶çš„ç»Ÿè®¡
            self.training_step_outputs.append({
                'loss': loss.detach(),
                'anomaly_prob': anomaly_prob.detach()
            })
            
            return loss
            
        except Exception as e:
            print(f"âŒ Training step error: {e}")
            print(f"   Batch keys: {batch.keys()}")
            if 'image' in batch:
                print(f"   Image shape: {batch['image'].shape}")
            if 'points' in batch:
                print(f"   Points shape: {batch['points'].shape}")
            raise e
    
    def validation_step(self, batch, batch_idx):
        """éªŒè¯æ­¥éª¤"""
        try:
            # å‰å‘ä¼ æ’­
            outputs = self(batch)
            
            # è®¡ç®—æŸå¤±
            if 'anomaly_label' in batch:
                anomaly_scores = outputs['anomaly_scores']
                labels = batch['anomaly_label']
                
                if isinstance(labels, dict):
                    labels = torch.zeros_like(anomaly_scores)
                
                loss = self.criterion(anomaly_scores, labels.float())
            else:
                anomaly_scores = outputs['anomaly_scores']
                loss = torch.mean(anomaly_scores)
            
            # è®°å½•éªŒè¯æŸå¤±
            self.log('val_loss', loss, prog_bar=True, logger=True, on_epoch=True)
            
            # è®°å½•å…¶ä»–æŒ‡æ ‡
            anomaly_prob = outputs['anomaly_probability'].mean()
            self.log('val_anomaly_prob', anomaly_prob, prog_bar=False, logger=True)
            
            # ä¿å­˜è¾“å‡º
            self.validation_step_outputs.append({
                'loss': loss.detach(),
                'anomaly_prob': anomaly_prob.detach(),
                'anomaly_scores': outputs['anomaly_scores'].detach().cpu(),
                'anomaly_heatmap': outputs['anomaly_heatmap'].detach().cpu()
            })
            
            return loss
            
        except Exception as e:
            print(f"âŒ Validation step error: {e}")
            raise e
    
    def on_train_epoch_end(self):
        """è®­ç»ƒepochç»“æŸ"""
        if len(self.training_step_outputs) > 0:
            avg_loss = torch.stack([x['loss'] for x in self.training_step_outputs]).mean()
            avg_prob = torch.stack([x['anomaly_prob'] for x in self.training_step_outputs]).mean()
            
            print(f"\nğŸ“Š Epoch {self.current_epoch} Training Summary:")
            print(f"   - Avg Loss: {avg_loss:.4f}")
            print(f"   - Avg Anomaly Prob: {avg_prob:.4f}")
            
            self.training_step_outputs.clear()
    
    def on_validation_epoch_end(self):
        """éªŒè¯epochç»“æŸ"""
        if len(self.validation_step_outputs) > 0:
            avg_loss = torch.stack([x['loss'] for x in self.validation_step_outputs]).mean()
            avg_prob = torch.stack([x['anomaly_prob'] for x in self.validation_step_outputs]).mean()
            
            print(f"   - Val Loss: {avg_loss:.4f}")
            print(f"   - Val Anomaly Prob: {avg_prob:.4f}")
            
            # å¯è§†åŒ–ç¬¬ä¸€ä¸ªbatchçš„å¼‚å¸¸çƒ­åŠ›å›¾
            if self.current_epoch % 5 == 0:  # æ¯5ä¸ªepochå¯è§†åŒ–ä¸€æ¬¡
                self._visualize_predictions(self.validation_step_outputs[0])
            
            self.validation_step_outputs.clear()
    
    def _visualize_predictions(self, outputs):
        """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""
        try:
            import matplotlib
            matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯
            import matplotlib.pyplot as plt
            
            # åˆ›å»ºå¯è§†åŒ–ç›®å½•
            vis_dir = Path('visualizations')
            vis_dir.mkdir(exist_ok=True)
            
            # è·å–å¼‚å¸¸çƒ­åŠ›å›¾
            heatmap = outputs['anomaly_heatmap'][0, 0].numpy()  # [X, Y]
            
            # ç»˜åˆ¶çƒ­åŠ›å›¾
            plt.figure(figsize=(10, 8))
            plt.imshow(heatmap, cmap='hot', interpolation='nearest')
            plt.colorbar(label='Anomaly Score')
            plt.title(f'Anomaly Heatmap - Epoch {self.current_epoch}')
            plt.xlabel('Y')
            plt.ylabel('X')
            
            # ä¿å­˜å›¾åƒ
            save_path = vis_dir / f'heatmap_epoch_{self.current_epoch:03d}.png'
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"   âœ… å¯è§†åŒ–ä¿å­˜è‡³: {save_path}")
            
        except Exception as e:
            print(f"   âš ï¸ å¯è§†åŒ–å¤±è´¥: {e}")
    
    def configure_optimizers(self):
        """é…ç½®ä¼˜åŒ–å™¨"""
        # åªä¼˜åŒ–å¯è®­ç»ƒçš„å‚æ•°
        trainable_params = [p for p in self.model.parameters() if p.requires_grad]
        
        optimizer = torch.optim.AdamW(
            trainable_params,
            lr=self.cfg.OPTIMIZER.LR,
            weight_decay=self.cfg.OPTIMIZER.WEIGHT_DECAY
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=self.cfg.OPTIMIZER.EPOCHS,
            eta_min=self.cfg.OPTIMIZER.LR * 0.01
        )
        
        return {
            'optimizer': optimizer,
            'lr_scheduler': {
                'scheduler': scheduler,
                'interval': 'epoch',
                'frequency': 1
            }
        }


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    parser = argparse.ArgumentParser(description='Train AnoVox Anomaly Detection Model')
    parser.add_argument('--config', type=str, default='muvo/configs/anovox_training.yml',
                       help='Path to config file')
    parser.add_argument('--data-root', type=str, 
                       default='/root/autodl-tmp/datasets/AnoVox/AnoVox_Dynamic_Mono_Town07',
                       help='Path to AnoVox dataset')
    parser.add_argument('--batch-size', type=int, default=2,
                       help='Batch size')
    parser.add_argument('--epochs', type=int, default=50,
                       help='Number of epochs')
    parser.add_argument('--gpus', type=int, default=1,
                       help='Number of GPUs')
    parser.add_argument('--resume', type=str, default=None,
                       help='Resume from checkpoint')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸš€ AnoVoxå¼‚å¸¸æ£€æµ‹è®­ç»ƒå¯åŠ¨")
    print("=" * 60)
    
    # åŠ è½½é…ç½®
    cfg = get_cfg()
    if os.path.exists(args.config):
        cfg.merge_from_file(args.config)
        print(f"âœ… åŠ è½½é…ç½®æ–‡ä»¶: {args.config}")
    else:
        print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    
    # æ›´æ–°é…ç½®
    cfg.BATCHSIZE = args.batch_size
    # epochsä»å‘½ä»¤è¡Œå‚æ•°è·å–ï¼Œä¸ä»é…ç½®æ–‡ä»¶
    
    # ç¡®ä¿å¼‚å¸¸æ£€æµ‹å¯ç”¨
    if not hasattr(cfg, 'ANOMALY_DETECTION'):
        from yacs.config import CfgNode as CN
        cfg.ANOMALY_DETECTION = CN()
    cfg.ANOMALY_DETECTION.ENABLED = True
    cfg.ANOMALY_DETECTION.FREEZE_BACKBONE = True
    
    # ç¦ç”¨é¢„è®­ç»ƒæƒé‡ä¸‹è½½ï¼ˆé¿å…ç½‘ç»œé—®é¢˜ï¼‰
    cfg.MODEL.ENCODER.PRETRAINED = False
    print("âš ï¸ ç¦ç”¨é¢„è®­ç»ƒæƒé‡ï¼ˆé¿å…ç½‘ç»œä¸‹è½½è¶…æ—¶ï¼‰")
    
    print(f"\nğŸ“Š è®­ç»ƒé…ç½®:")
    print(f"  - æ•°æ®é›†: {args.data_root}")
    print(f"  - Batch Size: {args.batch_size}")
    print(f"  - Epochs: {args.epochs}")
    print(f"  - GPUs: {args.gpus}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print(f"\nğŸ“ å‡†å¤‡æ•°æ®åŠ è½½å™¨...")
    
    try:
        train_loader = create_anovox_dataloader(
            data_root=args.data_root,
            split='train',
            batch_size=args.batch_size,
            num_workers=4,
            shuffle=True,
            load_voxel=True,
            load_anomaly_labels=True
        )
        print(f"âœ… è®­ç»ƒé›†åŠ è½½å™¨åˆ›å»ºæˆåŠŸ: {len(train_loader)} batches")
        
        val_loader = create_anovox_dataloader(
            data_root=args.data_root,
            split='train',  # AnoVoxå¯èƒ½æ²¡æœ‰æ˜ç¡®çš„val splitï¼Œå…ˆç”¨train
            batch_size=args.batch_size,
            num_workers=4,
            shuffle=False,
            load_voxel=True,
            load_anomaly_labels=True
        )
        print(f"âœ… éªŒè¯é›†åŠ è½½å™¨åˆ›å»ºæˆåŠŸ: {len(val_loader)} batches")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥: {e}")
        print(f"   è¯·æ£€æŸ¥æ•°æ®é›†è·¯å¾„: {args.data_root}")
        return
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸ åˆå§‹åŒ–æ¨¡å‹...")
    model = AnomalyDetectionModule(cfg)
    
    # è®¾ç½®å›è°ƒ
    callbacks = [
        # æ¨¡å‹æ£€æŸ¥ç‚¹
        ModelCheckpoint(
            dirpath='checkpoints',
            filename='anovox-anomaly-{epoch:02d}-{val_loss:.4f}',
            monitor='val_loss',
            mode='min',
            save_top_k=3,
            save_last=True,
            verbose=True
        ),
        
        # æ—©åœ
        EarlyStopping(
            monitor='val_loss',
            patience=15,
            mode='min',
            verbose=True
        ),
        
        # å­¦ä¹ ç‡ç›‘æ§
        LearningRateMonitor(logging_interval='epoch')
    ]
    
    # è®¾ç½®æ—¥å¿—
    logger = TensorBoardLogger(
        save_dir='lightning_logs',
        name='anovox_anomaly',
        default_hp_metric=False
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = pl.Trainer(
        max_epochs=args.epochs,
        accelerator='gpu' if torch.cuda.is_available() and args.gpus > 0 else 'cpu',
        devices=args.gpus if torch.cuda.is_available() and args.gpus > 0 else None,
        callbacks=callbacks,
        logger=logger,
        precision=16,  # æ··åˆç²¾åº¦è®­ç»ƒ
        gradient_clip_val=1.0,  # æ¢¯åº¦è£å‰ª
        log_every_n_steps=10,
        check_val_every_n_epoch=1,
        enable_progress_bar=True,
        enable_model_summary=True,
    )
    
    print(f"\nğŸ“ å¼€å§‹è®­ç»ƒ...")
    print(f"ğŸ’¡ ä½¿ç”¨TensorBoardç›‘æ§è®­ç»ƒ: tensorboard --logdir lightning_logs")
    print(f"ğŸ’¡ å¯è§†åŒ–ç»“æœä¿å­˜åœ¨: visualizations/")
    print("=" * 60)
    
    # å¼€å§‹è®­ç»ƒ
    try:
        trainer.fit(
            model,
            train_dataloaders=train_loader,
            val_dataloaders=val_loader,
            ckpt_path=args.resume
        )
        
        print("\n" + "=" * 60)
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print("=" * 60)
        print(f"\nğŸ“Š æœ€ä½³æ¨¡å‹: {trainer.checkpoint_callback.best_model_path}")
        print(f"ğŸ“ˆ æœ€ä½³éªŒè¯æŸå¤±: {trainer.checkpoint_callback.best_model_score:.4f}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

