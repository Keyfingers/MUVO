"""
ğŸ¯ åœºæ™¯çº§å¼‚å¸¸æ£€æµ‹è®­ç»ƒè„šæœ¬ï¼ˆæ–¹æ¡ˆBï¼‰

å…³é”®æ”¹è¿›ï¼š
1. ä»ç‚¹çº§é¢„æµ‹æ”¹ä¸ºåœºæ™¯çº§é¢„æµ‹ï¼ˆä¸€ä¸ªåœºæ™¯ä¸€ä¸ªæ ‡ç­¾ï¼‰
2. ä½¿ç”¨100%å¯é çš„ anomaly_is_alive æ ‡ç­¾
3. å…¨å±€æ± åŒ–èåˆç‚¹äº‘ç‰¹å¾
4. ç®€å•é«˜æ•ˆï¼Œä¸€å®šèƒ½work

ä¼˜åŠ¿ï¼š
- æ ‡ç­¾å¯é æ€§ï¼š100%
- è®­ç»ƒç¨³å®šæ€§ï¼šé«˜
- ç±»åˆ«ä¸å¹³è¡¡ï¼šå¯æ§
- å®ç°å¤æ‚åº¦ï¼šä½
"""

import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from tqdm import tqdm
import numpy as np
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from muvo.config import _C
from muvo.dataset.anovox_dataset import AnoVoxDataset, collate_fn


class SceneLevelAnomalyDetector(nn.Module):
    """
    åœºæ™¯çº§å¼‚å¸¸æ£€æµ‹å™¨
    
    æ¶æ„ï¼š
    1. å›¾åƒç‰¹å¾æå– + ç‚¹äº‘ç‰¹å¾æå–
    2. å…¨å±€æ± åŒ–èåˆ
    3. åœºæ™¯çº§åˆ†ç±»å¤´
    """
    
    def __init__(self, cfg):
        super().__init__()
        self.cfg = cfg
        
        # ç®€åŒ–ç‰ˆç‰¹å¾æå–å™¨
        # å›¾åƒåˆ†æ”¯
        self.image_encoder = nn.Sequential(
            nn.Conv2d(3, 64, 7, stride=2, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2, padding=1),
            
            # ResBlock 1
            self._make_layer(64, 128, 2),
            
            # ResBlock 2
            self._make_layer(128, 256, 2),
            
            # ResBlock 3
            self._make_layer(256, 512, 2),
            
            # å…¨å±€å¹³å‡æ± åŒ–
            nn.AdaptiveAvgPool2d((1, 1))
        )
        
        # ç‚¹äº‘åˆ†æ”¯ï¼ˆç®€åŒ–ç‰ˆPointNetï¼‰
        self.point_encoder = nn.Sequential(
            nn.Conv1d(4, 64, 1),
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True),
            
            nn.Conv1d(64, 128, 1),
            nn.BatchNorm1d(128),
            nn.ReLU(inplace=True),
            
            nn.Conv1d(128, 256, 1),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            
            nn.Conv1d(256, 512, 1),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
        )
        
        # èåˆåçš„åˆ†ç±»å¤´
        self.classifier = nn.Sequential(
            nn.Linear(512 + 512, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            
            nn.Linear(256, 1)  # äºŒåˆ†ç±»ï¼šæœ‰/æ— å¼‚å¸¸
        )
        
        self._initialize_weights()
    
    def _make_layer(self, in_channels, out_channels, stride):
        """åˆ›å»ºä¸€ä¸ªResNetå±‚"""
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1),
            nn.BatchNorm2d(out_channels),
        )
    
    def _initialize_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv1d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, batch):
        """
        Args:
            batch: dict with keys:
                - image: [B, 3, H, W]
                - points: [B, N, 4]
        
        Returns:
            dict with keys:
                - scene_logit: [B, 1] åœºæ™¯å¼‚å¸¸logit
                - scene_prob: [B, 1] åœºæ™¯å¼‚å¸¸æ¦‚ç‡
        """
        image = batch['image']  # [B, 3, H, W]
        points = batch['points']  # [B, N, 4]
        
        B = image.shape[0]
        
        # 1. å›¾åƒç‰¹å¾æå–
        img_feat = self.image_encoder(image)  # [B, 512, 1, 1]
        img_feat = img_feat.view(B, -1)  # [B, 512]
        
        # 2. ç‚¹äº‘ç‰¹å¾æå–
        points_t = points.permute(0, 2, 1)  # [B, 4, N]
        point_feat = self.point_encoder(points_t)  # [B, 512, N]
        
        # å…¨å±€æœ€å¤§æ± åŒ–
        point_feat = torch.max(point_feat, dim=2)[0]  # [B, 512]
        
        # 3. ç‰¹å¾èåˆ
        fused_feat = torch.cat([img_feat, point_feat], dim=1)  # [B, 1024]
        
        # 4. åœºæ™¯çº§åˆ†ç±»
        scene_logit = self.classifier(fused_feat)  # [B, 1]
        scene_prob = torch.sigmoid(scene_logit)  # [B, 1]
        
        return {
            'scene_logit': scene_logit,
            'scene_prob': scene_prob,
            'image_feat': img_feat,
            'point_feat': point_feat
        }


def extract_scene_labels(batch):
    """
    ä»batchä¸­æå–åœºæ™¯çº§æ ‡ç­¾
    
    Args:
        batch: dict with 'anomaly_label' key
    
    Returns:
        labels: [B] tensor, 1.0 if anomaly, 0.0 if normal
    """
    anomaly_labels = batch.get('anomaly_label', [])
    
    labels = []
    for label_dict in anomaly_labels:
        if isinstance(label_dict, dict):
            anomaly_is_alive = label_dict.get('anomaly_is_alive', 'False')
            # è½¬æ¢ä¸ºå¸ƒå°”å€¼
            if isinstance(anomaly_is_alive, str):
                has_anomaly = (anomaly_is_alive.lower() == 'true')
            else:
                has_anomaly = bool(anomaly_is_alive)
            labels.append(1.0 if has_anomaly else 0.0)
        else:
            labels.append(0.0)
    
    return torch.tensor(labels, dtype=torch.float32)


def train_epoch(model, dataloader, optimizer, device, epoch):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    
    total_loss = 0
    correct = 0
    total = 0
    tp = 0  # True Positives
    fp = 0  # False Positives
    fn = 0  # False Negatives
    tn = 0  # True Negatives
    
    pbar = tqdm(dataloader, desc=f'Epoch {epoch}')
    
    for batch_idx, batch in enumerate(pbar):
        # å‡†å¤‡æ•°æ®
        image = batch['image'].to(device)
        points = batch['points'].to(device)
        
        # æå–åœºæ™¯çº§æ ‡ç­¾
        labels = extract_scene_labels(batch).to(device)  # [B]
        
        B = labels.shape[0]
        
        # å‰å‘ä¼ æ’­
        model_input = {
            'image': image,
            'points': points
        }
        outputs = model(model_input)
        scene_logit = outputs['scene_logit'].squeeze()  # [B]
        
        # è®¡ç®—lossï¼ˆä½¿ç”¨pos_weightå¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼‰
        # ç»Ÿè®¡æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹
        pos_count = (labels == 1.0).sum().item()
        neg_count = (labels == 0.0).sum().item()
        
        if pos_count > 0:
            pos_weight = torch.tensor([neg_count / pos_count], device=device)
        else:
            pos_weight = torch.tensor([1.0], device=device)
        
        loss = F.binary_cross_entropy_with_logits(
            scene_logit,
            labels,
            pos_weight=pos_weight
        )
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # ç»Ÿè®¡
        total_loss += loss.item()
        
        predictions = (torch.sigmoid(scene_logit) > 0.5).float()
        correct += (predictions == labels).sum().item()
        total += B
        
        # è®¡ç®—TP, FP, FN, TN
        for i in range(B):
            pred = predictions[i].item()
            label = labels[i].item()
            
            if pred == 1.0 and label == 1.0:
                tp += 1
            elif pred == 1.0 and label == 0.0:
                fp += 1
            elif pred == 0.0 and label == 1.0:
                fn += 1
            else:
                tn += 1
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = 100.0 * correct / total if total > 0 else 0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        
        pbar.set_postfix({
            'loss': f'{loss.item():.4f}',
            'acc': f'{accuracy:.2f}%',
            'recall': f'{100*recall:.2f}%',
            'pos': f'{pos_count}/{B}'
        })
    
    # Epochç»Ÿè®¡
    avg_loss = total_loss / len(dataloader)
    accuracy = 100.0 * correct / total
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    
    print(f"\nğŸ“Š Epoch {epoch} Summary:")
    print(f"   Loss: {avg_loss:.4f}")
    print(f"   Accuracy: {accuracy:.2f}%")
    print(f"   Precision: {100*precision:.2f}%")
    print(f"   Recall: {100*recall:.2f}%")
    print(f"   F1-Score: {100*f1:.2f}%")
    print(f"   TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}")
    
    return {
        'loss': avg_loss,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }


def main():
    print("=" * 80)
    print("ğŸ¯ åœºæ™¯çº§å¼‚å¸¸æ£€æµ‹è®­ç»ƒï¼ˆæ–¹æ¡ˆBï¼‰")
    print("=" * 80)
    
    # é…ç½®
    cfg = _C.clone()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ–¥ï¸  è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®é›†
    print(f"\nğŸ“¦ åŠ è½½æ•°æ®é›†...")
    train_dataset = AnoVoxDataset(
        data_root='/root/autodl-tmp/datasets/AnoVox',
        split='train',
        dataset_types=['Dynamic_Mono_Town07', 'Normality_Mono_Town07'],
        train_ratio=0.8,
        load_anomaly_labels=True,
        load_voxel=False  # åœºæ™¯çº§ä¸éœ€è¦ä½“ç´ 
    )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=8,
        shuffle=True,
        collate_fn=collate_fn,
        num_workers=4,
        pin_memory=True
    )
    
    print(f"âœ… è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬, {len(train_loader)} æ‰¹æ¬¡")
    
    # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
    print(f"\nğŸ“Š ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ...")
    anomaly_count = 0
    for i in range(min(1000, len(train_dataset))):
        sample = train_dataset[i]
        label = sample.get('anomaly_label', {})
        if isinstance(label, dict):
            anomaly_is_alive = label.get('anomaly_is_alive', 'False')
            if isinstance(anomaly_is_alive, str) and anomaly_is_alive.lower() == 'true':
                anomaly_count += 1
            elif anomaly_is_alive:
                anomaly_count += 1
    
    print(f"   å‰1000ä¸ªæ ·æœ¬ä¸­å¼‚å¸¸åœºæ™¯: {anomaly_count} ({100*anomaly_count/1000:.1f}%)")
    print(f"   å»ºè®®pos_weight: {(1000-anomaly_count)/anomaly_count:.1f}")
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸  åˆ›å»ºåœºæ™¯çº§å¼‚å¸¸æ£€æµ‹æ¨¡å‹...")
    model = SceneLevelAnomalyDetector(cfg).to(device)
    
    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)
    
    # è®­ç»ƒ
    num_epochs = 30
    best_recall = 0
    
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ {num_epochs} epochs...")
    print("=" * 80)
    
    for epoch in range(1, num_epochs + 1):
        metrics = train_epoch(model, train_loader, optimizer, device, epoch)
        scheduler.step()
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if metrics['recall'] > best_recall:
            best_recall = metrics['recall']
            checkpoint_path = f'checkpoints/scene_level_best.pth'
            os.makedirs('checkpoints', exist_ok=True)
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'metrics': metrics
            }, checkpoint_path)
            print(f"\nğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (Recall: {100*best_recall:.2f}%)")
        
        print("=" * 80)
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼")
    print(f"   æœ€ä½³Recall: {100*best_recall:.2f}%")
    print(f"   æ¨¡å‹ä¿å­˜åœ¨: checkpoints/scene_level_best.pth")


if __name__ == '__main__':
    main()


