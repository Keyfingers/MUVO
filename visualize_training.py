"""
è®­ç»ƒå¯è§†åŒ–è„šæœ¬
å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦å’Œç”Ÿæˆå¯è§†åŒ–ç»“æœ
"""

import os
import time
import argparse
from pathlib import Path
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import numpy as np
from tensorboard.backend.event_processing import event_accumulator


def plot_training_curves(log_dir, save_dir='visualizations'):
    """
    ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    """
    save_dir = Path(save_dir)
    save_dir.mkdir(exist_ok=True)
    
    # æŸ¥æ‰¾æœ€æ–°çš„äº‹ä»¶æ–‡ä»¶
    log_path = Path(log_dir)
    event_files = list(log_path.rglob('events.out.tfevents.*'))
    
    if not event_files:
        print(f"âš ï¸ æœªæ‰¾åˆ°TensorBoardæ—¥å¿—æ–‡ä»¶: {log_dir}")
        return
    
    # ä½¿ç”¨æœ€æ–°çš„äº‹ä»¶æ–‡ä»¶
    latest_event = max(event_files, key=lambda p: p.stat().st_mtime)
    print(f"ğŸ“Š è¯»å–æ—¥å¿—: {latest_event}")
    
    # åŠ è½½äº‹ä»¶
    ea = event_accumulator.EventAccumulator(str(latest_event.parent))
    ea.Reload()
    
    # è·å–å¯ç”¨çš„æ ‡é‡
    scalar_tags = ea.Tags()['scalars']
    print(f"âœ… å¯ç”¨æŒ‡æ ‡: {scalar_tags}")
    
    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('AnoVox Anomaly Detection Training Progress', fontsize=16, fontweight='bold')
    
    # 1. è®­ç»ƒå’ŒéªŒè¯æŸå¤±
    ax = axes[0, 0]
    if 'train_loss_epoch' in scalar_tags:
        train_loss = [(s.step, s.value) for s in ea.Scalars('train_loss_epoch')]
        steps, values = zip(*train_loss)
        ax.plot(steps, values, 'b-', label='Train Loss', linewidth=2)
    
    if 'val_loss' in scalar_tags:
        val_loss = [(s.step, s.value) for s in ea.Scalars('val_loss')]
        steps, values = zip(*val_loss)
        ax.plot(steps, values, 'r-', label='Val Loss', linewidth=2)
    
    ax.set_xlabel('Epoch', fontsize=12)
    ax.set_ylabel('Loss', fontsize=12)
    ax.set_title('Training & Validation Loss', fontsize=14, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3)
    
    # 2. å¼‚å¸¸æ¦‚ç‡
    ax = axes[0, 1]
    if 'train_anomaly_prob' in scalar_tags:
        train_prob = [(s.step, s.value) for s in ea.Scalars('train_anomaly_prob')]
        steps, values = zip(*train_prob)
        ax.plot(steps, values, 'g-', label='Train Anomaly Prob', linewidth=2)
    
    if 'val_anomaly_prob' in scalar_tags:
        val_prob = [(s.step, s.value) for s in ea.Scalars('val_anomaly_prob')]
        steps, values = zip(*val_prob)
        ax.plot(steps, values, 'm-', label='Val Anomaly Prob', linewidth=2)
    
    ax.set_xlabel('Step', fontsize=12)
    ax.set_ylabel('Anomaly Probability', fontsize=12)
    ax.set_title('Anomaly Detection Probability', fontsize=14, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3)
    
    # 3. å­¦ä¹ ç‡
    ax = axes[1, 0]
    if 'lr-AdamW' in scalar_tags:
        lr_data = [(s.step, s.value) for s in ea.Scalars('lr-AdamW')]
        steps, values = zip(*lr_data)
        ax.plot(steps, values, 'orange', linewidth=2)
        ax.set_xlabel('Epoch', fontsize=12)
        ax.set_ylabel('Learning Rate', fontsize=12)
        ax.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.set_yscale('log')
    
    # 4. è®­ç»ƒæ­¥æŸå¤±ï¼ˆè¯¦ç»†ï¼‰
    ax = axes[1, 1]
    if 'train_loss_step' in scalar_tags:
        train_loss_step = [(s.step, s.value) for s in ea.Scalars('train_loss_step')]
        steps, values = zip(*train_loss_step)
        # ä½¿ç”¨ç§»åŠ¨å¹³å‡å¹³æ»‘æ›²çº¿
        window = min(50, len(values) // 10)
        if window > 0:
            smoothed = np.convolve(values, np.ones(window)/window, mode='valid')
            ax.plot(steps[:len(smoothed)], smoothed, 'b-', linewidth=2, alpha=0.7)
        ax.set_xlabel('Training Step', fontsize=12)
        ax.set_ylabel('Loss', fontsize=12)
        ax.set_title('Training Loss (Smoothed)', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    save_path = save_dir / 'training_curves.png'
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"âœ… è®­ç»ƒæ›²çº¿ä¿å­˜è‡³: {save_path}")
    plt.close()
    
    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    generate_stats_report(ea, scalar_tags, save_dir)


def generate_stats_report(ea, scalar_tags, save_dir):
    """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
    report_path = save_dir / 'training_stats.txt'
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("=" * 60 + "\n")
        f.write("AnoVoxå¼‚å¸¸æ£€æµ‹è®­ç»ƒç»Ÿè®¡æŠ¥å‘Š\n")
        f.write("=" * 60 + "\n\n")
        
        # è®­ç»ƒæŸå¤±ç»Ÿè®¡
        if 'train_loss_epoch' in scalar_tags:
            train_loss = [s.value for s in ea.Scalars('train_loss_epoch')]
            f.write(f"ğŸ“Š è®­ç»ƒæŸå¤± (Train Loss):\n")
            f.write(f"   - åˆå§‹: {train_loss[0]:.4f}\n")
            f.write(f"   - æœ€ç»ˆ: {train_loss[-1]:.4f}\n")
            f.write(f"   - æœ€å°: {min(train_loss):.4f}\n")
            f.write(f"   - å¹³å‡: {np.mean(train_loss):.4f}\n")
            f.write(f"   - æ”¹å–„: {((train_loss[0] - train_loss[-1]) / train_loss[0] * 100):.1f}%\n\n")
        
        # éªŒè¯æŸå¤±ç»Ÿè®¡
        if 'val_loss' in scalar_tags:
            val_loss = [s.value for s in ea.Scalars('val_loss')]
            f.write(f"ğŸ“Š éªŒè¯æŸå¤± (Validation Loss):\n")
            f.write(f"   - åˆå§‹: {val_loss[0]:.4f}\n")
            f.write(f"   - æœ€ç»ˆ: {val_loss[-1]:.4f}\n")
            f.write(f"   - æœ€å°: {min(val_loss):.4f}\n")
            f.write(f"   - å¹³å‡: {np.mean(val_loss):.4f}\n")
            f.write(f"   - æ”¹å–„: {((val_loss[0] - val_loss[-1]) / val_loss[0] * 100):.1f}%\n\n")
        
        # å¼‚å¸¸æ¦‚ç‡ç»Ÿè®¡
        if 'train_anomaly_prob' in scalar_tags:
            train_prob = [s.value for s in ea.Scalars('train_anomaly_prob')]
            f.write(f"ğŸ“Š å¼‚å¸¸æ¦‚ç‡ (Anomaly Probability):\n")
            f.write(f"   - è®­ç»ƒé›†å¹³å‡: {np.mean(train_prob):.4f}\n")
        
        if 'val_anomaly_prob' in scalar_tags:
            val_prob = [s.value for s in ea.Scalars('val_anomaly_prob')]
            f.write(f"   - éªŒè¯é›†å¹³å‡: {np.mean(val_prob):.4f}\n\n")
        
        f.write("=" * 60 + "\n")
    
    print(f"âœ… ç»Ÿè®¡æŠ¥å‘Šä¿å­˜è‡³: {report_path}")
    
    # æ‰“å°åˆ°æ§åˆ¶å°
    with open(report_path, 'r', encoding='utf-8') as f:
        print(f.read())


def create_visualization_grid(vis_dir='visualizations', output_path='visualizations/results_grid.png'):
    """
    åˆ›å»ºå¯è§†åŒ–ç½‘æ ¼ - å±•ç¤ºå¤šä¸ªepochçš„å¼‚å¸¸çƒ­åŠ›å›¾
    """
    vis_dir = Path(vis_dir)
    output_path = Path(output_path)
    
    # æŸ¥æ‰¾æ‰€æœ‰çƒ­åŠ›å›¾
    heatmap_files = sorted(vis_dir.glob('heatmap_epoch_*.png'))
    
    if not heatmap_files:
        print(f"âš ï¸ æœªæ‰¾åˆ°çƒ­åŠ›å›¾æ–‡ä»¶")
        return
    
    # é€‰æ‹©å‡ ä¸ªå…³é”®epochæ˜¾ç¤º
    num_display = min(9, len(heatmap_files))
    indices = np.linspace(0, len(heatmap_files)-1, num_display, dtype=int)
    selected_files = [heatmap_files[i] for i in indices]
    
    # åˆ›å»ºç½‘æ ¼
    rows = int(np.ceil(np.sqrt(num_display)))
    cols = int(np.ceil(num_display / rows))
    
    fig, axes = plt.subplots(rows, cols, figsize=(cols*4, rows*4))
    fig.suptitle('Anomaly Detection Progress Across Epochs', fontsize=16, fontweight='bold')
    
    if rows == 1 and cols == 1:
        axes = np.array([[axes]])
    elif rows == 1 or cols == 1:
        axes = axes.reshape(rows, cols)
    
    for idx, (ax, img_path) in enumerate(zip(axes.flat, selected_files)):
        # è¯»å–å›¾åƒ
        img = plt.imread(img_path)
        ax.imshow(img)
        
        # ä»æ–‡ä»¶åæå–epoch
        epoch = int(img_path.stem.split('_')[-1])
        ax.set_title(f'Epoch {epoch}', fontsize=12)
        ax.axis('off')
    
    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(len(selected_files), rows * cols):
        axes.flat[idx].axis('off')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"âœ… å¯è§†åŒ–ç½‘æ ¼ä¿å­˜è‡³: {output_path}")
    plt.close()


def monitor_training(log_dir='lightning_logs', interval=60):
    """
    æŒç»­ç›‘æ§è®­ç»ƒè¿›åº¦
    
    Args:
        log_dir: TensorBoardæ—¥å¿—ç›®å½•
        interval: æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰
    """
    print("=" * 60)
    print("ğŸ” å¼€å§‹ç›‘æ§è®­ç»ƒè¿›åº¦")
    print(f"ğŸ“ æ—¥å¿—ç›®å½•: {log_dir}")
    print(f"â° æ›´æ–°é—´éš”: {interval}ç§’")
    print("=" * 60)
    print("\nğŸ’¡ æŒ‰ Ctrl+C åœæ­¢ç›‘æ§\n")
    
    try:
        while True:
            # æŸ¥æ‰¾æœ€æ–°çš„ç‰ˆæœ¬ç›®å½•
            log_path = Path(log_dir) / 'anovox_anomaly'
            if not log_path.exists():
                print(f"âš ï¸ ç­‰å¾…è®­ç»ƒå¼€å§‹... ({log_path})")
                time.sleep(interval)
                continue
            
            # è·å–æœ€æ–°ç‰ˆæœ¬
            versions = sorted([d for d in log_path.iterdir() if d.is_dir() and d.name.startswith('version_')])
            if not versions:
                print(f"âš ï¸ ç­‰å¾…è®­ç»ƒå¼€å§‹...")
                time.sleep(interval)
                continue
            
            latest_version = versions[-1]
            
            # æ›´æ–°å¯è§†åŒ–
            print(f"\nğŸ”„ æ›´æ–°å¯è§†åŒ–... ({time.strftime('%H:%M:%S')})")
            plot_training_curves(latest_version)
            create_visualization_grid()
            
            time.sleep(interval)
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç›‘æ§å·²åœæ­¢")


def main():
    parser = argparse.ArgumentParser(description='Visualize Training Progress')
    parser.add_argument('--log-dir', type=str, default='lightning_logs',
                       help='TensorBoard log directory')
    parser.add_argument('--monitor', action='store_true',
                       help='Continuously monitor training')
    parser.add_argument('--interval', type=int, default=60,
                       help='Update interval in seconds (for monitor mode)')
    
    args = parser.parse_args()
    
    if args.monitor:
        # æŒç»­ç›‘æ§æ¨¡å¼
        monitor_training(args.log_dir, args.interval)
    else:
        # å•æ¬¡å¯è§†åŒ–æ¨¡å¼
        log_path = Path(args.log_dir) / 'anovox_anomaly'
        if log_path.exists():
            versions = sorted([d for d in log_path.iterdir() if d.is_dir() and d.name.startswith('version_')])
            if versions:
                latest_version = versions[-1]
                print(f"ğŸ“Š ç”Ÿæˆå¯è§†åŒ–: {latest_version}")
                plot_training_curves(latest_version)
                create_visualization_grid()
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒç‰ˆæœ¬")
        else:
            print(f"âš ï¸ æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {log_path}")


if __name__ == '__main__':
    main()

