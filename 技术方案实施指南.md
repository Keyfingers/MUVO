# åŸºäºè·¨æ¨¡æ€æ³¨æ„åŠ›çš„é“è·¯å¼‚å¸¸æ£€æµ‹ - æŠ€æœ¯æ–¹æ¡ˆå®æ–½æŒ‡å—

> **é¡¹ç›®å®šä½**ï¼šé’ˆå¯¹AnoVoxåŸºå‡†æ•°æ®é›†ï¼Œæå‡ºå¹¶å®ç°ä¸€ç§åŸºäºè·¨æ¨¡æ€æ³¨æ„åŠ›èåˆçš„é“è·¯å¼‚å¸¸æ£€æµ‹æ–¹æ³•
> 
> **æ ¸å¿ƒåˆ›æ–°**ï¼šç”¨è½»é‡çº§è·¨æ¨¡æ€æ³¨æ„åŠ›æ¨¡å—å–ä»£ç®€å•ç‰¹å¾æ‹¼æ¥ï¼Œæ˜¾è‘—æå‡å¤šæ¨¡æ€èåˆæ•ˆç‡

---

## ğŸ“š ç›®å½•

1. [é¡¹ç›®èƒŒæ™¯ä¸åŠ¨æœº](#1-é¡¹ç›®èƒŒæ™¯ä¸åŠ¨æœº)
2. [å½“å‰é¡¹ç›®çŠ¶æ€](#2-å½“å‰é¡¹ç›®çŠ¶æ€)
3. [æŠ€æœ¯æ–¹æ¡ˆæ¶æ„](#3-æŠ€æœ¯æ–¹æ¡ˆæ¶æ„)
4. [æ•°æ®é›†è¯´æ˜](#4-æ•°æ®é›†è¯´æ˜)
5. [å®æ–½æ­¥éª¤](#5-å®æ–½æ­¥éª¤)
6. [å®éªŒè®¾è®¡](#6-å®éªŒè®¾è®¡)
7. [é¢„æœŸæˆæœ](#7-é¢„æœŸæˆæœ)

---

## 1. é¡¹ç›®èƒŒæ™¯ä¸åŠ¨æœº

### 1.1 ç ”ç©¶é—®é¢˜

**æ ¸å¿ƒé—®é¢˜**ï¼šå¦‚ä½•è®¾è®¡ä¸€ä¸ªæ›´æœ‰æ•ˆçš„å¤šæ¨¡æ€èåˆæœºåˆ¶ï¼ŒçœŸæ­£é‡Šæ”¾å›¾åƒ+ç‚¹äº‘æ•°æ®åœ¨é“è·¯å¼‚å¸¸æ£€æµ‹ä¸­çš„æ½œåŠ›ï¼Ÿ

**å­¦æœ¯ç¼ºå£**ï¼š
- **AnoVoxåŸºå‡†**ï¼šæœ€æ–°ã€æœ€å¤§è§„æ¨¡çš„è‡ªåŠ¨é©¾é©¶å¼‚å¸¸æ£€æµ‹æ•°æ®é›†
- **ç°æœ‰é—®é¢˜**ï¼šAnoVoxè®ºæ–‡æå‡ºçš„å¤šæ¨¡æ€èåˆåŸºçº¿ï¼ˆç®€å•ç‰¹å¾æ‹¼æ¥ï¼‰ï¼Œç›¸æ¯”å•æ¨¡æ€æ–¹æ³•æ€§èƒ½æå‡æœ‰é™
- **æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆ**ï¼šè·¨æ¨¡æ€æ³¨æ„åŠ›èåˆæœºåˆ¶

### 1.2 ç ”ç©¶æ„ä¹‰

1. **å®‰å…¨æ€§**ï¼šé“è·¯å¼‚å¸¸æ£€æµ‹æ˜¯è‡ªåŠ¨é©¾é©¶çš„æœ€åä¸€é“å®‰å…¨é˜²çº¿
2. **å‰æ²¿æ€§**ï¼šé‡‡ç”¨å½“å‰ä¸»æµçš„Transformer/Attentionæœºåˆ¶
3. **å®ç”¨æ€§**ï¼šåŸºäºå¼€æ”¾æ•°æ®é›†å’ŒåŸºå‡†ï¼Œç ”ç©¶æˆæœå¯å¤ç°ã€å¯å¯¹æ¯”

---

## 2. å½“å‰é¡¹ç›®çŠ¶æ€

### 2.1 å·²å®Œæˆå·¥ä½œ âœ…

| é¡¹ç›® | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| ç¯å¢ƒæ­å»º | âœ… å®Œæˆ | Python 3.8 + PyTorch + Lightning |
| ä¾èµ–å®‰è£… | âœ… å®Œæˆ | timm, torch_scatter, open3dç­‰ |
| MUVOä»£ç åº“ | âœ… å®Œæˆ | åŸºç¡€æ¡†æ¶å·²å°±ç»ª |
| **AnoVoxæ•°æ®é›†** | âœ… å®Œæˆ | å·²ä¸‹è½½Town07æ•°æ®ï¼ˆ17.5GBï¼‰ |
| **æ•°æ®åŠ è½½å™¨** | âœ… å®Œæˆ | å®ç°AnoVoxDataseté€‚é…å™¨ |
| æ•°æ®éªŒè¯ | âœ… å®Œæˆ | æˆåŠŸåŠ è½½4200ä¸ªæ ·æœ¬ |

### 2.2 æ•°æ®é›†ç»Ÿè®¡

```
æ•°æ®é›†: AnoVox_Dynamic_Mono_Town07
- åœºæ™¯æ•°: 22ä¸ª
- æ€»æ ·æœ¬æ•°: 4200å¸§
- å›¾åƒåˆ†è¾¨ç‡: 768Ã—512
- ç‚¹äº‘ç‚¹æ•°: ~92,000ç‚¹/å¸§
- å­˜å‚¨æ ¼å¼:
  â”œâ”€â”€ å›¾åƒ: PNG (RGB)
  â”œâ”€â”€ ç‚¹äº‘: NPY (x,y,z)
  â”œâ”€â”€ ä½“ç´ : NPZ (3D grid)
  â””â”€â”€ æ ‡æ³¨: JSON (anomaly labels)
```

---

## 3. æŠ€æœ¯æ–¹æ¡ˆæ¶æ„

### 3.1 æ•´ä½“æµç¨‹å›¾

```
è¾“å…¥æ•°æ®
  â”œâ”€â”€ RGBå›¾åƒ (768Ã—512Ã—3)
  â””â”€â”€ ç‚¹äº‘ (NÃ—3)
      â†“
ç‰¹å¾æå–ï¼ˆå†»ç»“éª¨å¹²ç½‘ç»œï¼‰
  â”œâ”€â”€ ResNet18 (å›¾åƒç‰¹å¾)  â†’ F_img [B, C, H, W]
  â””â”€â”€ Cylinder3D (ç‚¹äº‘ç‰¹å¾) â†’ F_pc [B, C, X, Y, Z]
      â†“
ã€æ ¸å¿ƒåˆ›æ–°ã€‘è·¨æ¨¡æ€æ³¨æ„åŠ›èåˆæ¨¡å—
  â”œâ”€â”€ 3Dä½ç½®ç¼–ç 
  â”œâ”€â”€ ç‰¹å¾ç©ºé—´å¯¹é½ (æŠ•å½±F_imgåˆ°ä½“ç´ ç©ºé—´)
  â”œâ”€â”€ è·¨æ¨¡æ€æ³¨æ„åŠ›
  â”‚   â”œâ”€â”€ Query: F_pc (ç‚¹äº‘ç‰¹å¾)
  â”‚   â”œâ”€â”€ Key/Value: F_img_aligned (å¯¹é½çš„å›¾åƒç‰¹å¾)
  â”‚   â””â”€â”€ Multi-Head Attention
  â”œâ”€â”€ æ®‹å·®è¿æ¥
  â”œâ”€â”€ å±‚å½’ä¸€åŒ–
  â””â”€â”€ å‰é¦ˆç½‘ç»œ (FFN)
      â†“
èåˆç‰¹å¾ F_fused [B, C, X, Y, Z]
      â†“
è½»é‡çº§å¼‚å¸¸æ£€æµ‹å¤´
  â”œâ”€â”€ 3Då·ç§¯å±‚ / MLP
  â””â”€â”€ è¾“å‡º: å¼‚å¸¸åˆ†æ•° [B, X, Y, Z]
      â†“
è¾“å‡º
  â”œâ”€â”€ ä½“ç´ çº§å¼‚å¸¸æ£€æµ‹
  â””â”€â”€ è¯„ä¼°æŒ‡æ ‡: AUROC, AUPRC
```

### 3.2 æ ¸å¿ƒæ¨¡å—è¯¦è§£

#### æ¨¡å—1: ç‰¹å¾æå–å™¨ï¼ˆå¤ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰

```python
# å›¾åƒåˆ†æ”¯
backbone_image = ResNet18(pretrained=True, frozen=True)
F_img = backbone_image(rgb_image)  # [B, 512, H/32, W/32]

# ç‚¹äº‘åˆ†æ”¯
backbone_lidar = Cylinder3D(pretrained=True, frozen=True)
F_pc = backbone_lidar(point_cloud)  # [B, 128, X, Y, Z]
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- å†»ç»“æƒé‡ â†’ å¤§å¹…é™ä½è®¡ç®—æˆæœ¬
- ä½¿ç”¨æˆç†Ÿæ¨¡å‹ â†’ ä¿è¯ç‰¹å¾è´¨é‡
- èšç„¦æ ¸å¿ƒåˆ›æ–° â†’ èåˆæœºåˆ¶è®¾è®¡

#### æ¨¡å—2: è·¨æ¨¡æ€æ³¨æ„åŠ›èåˆï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰

```python
class CrossModalAttentionFusion(nn.Module):
    def __init__(self, pc_dim, img_dim, hidden_dim, num_heads):
        # 1. ç‰¹å¾ç»´åº¦å¯¹é½
        self.pc_proj = nn.Linear(pc_dim, hidden_dim)
        self.img_proj = nn.Linear(img_dim, hidden_dim)
        
        # 2. 3Dä½ç½®ç¼–ç 
        self.pos_encoding_3d = PositionalEncoding3D(hidden_dim)
        
        # 3. å¤šå¤´æ³¨æ„åŠ›
        self.multihead_attn = nn.MultiheadAttention(
            embed_dim=hidden_dim,
            num_heads=num_heads,
            batch_first=True
        )
        
        # 4. å‰é¦ˆç½‘ç»œ
        self.ffn = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim * 4),
            nn.GELU(),
            nn.Linear(hidden_dim * 4, hidden_dim)
        )
        
        # 5. å½’ä¸€åŒ–
        self.norm1 = nn.LayerNorm(hidden_dim)
        self.norm2 = nn.LayerNorm(hidden_dim)
    
    def forward(self, F_pc, F_img_aligned):
        # æŠ•å½±åˆ°ç»Ÿä¸€ç»´åº¦
        Q = self.pc_proj(F_pc)  # ç‚¹äº‘ä½œä¸ºQuery
        K = V = self.img_proj(F_img_aligned)  # å›¾åƒä½œä¸ºKey/Value
        
        # æ·»åŠ ä½ç½®ç¼–ç 
        Q = Q + self.pos_encoding_3d(Q)
        K = K + self.pos_encoding_3d(K)
        
        # æ³¨æ„åŠ›èåˆ
        attn_output, _ = self.multihead_attn(Q, K, V)
        
        # æ®‹å·®è¿æ¥ + å½’ä¸€åŒ–
        F_fused = self.norm1(Q + attn_output)
        
        # å‰é¦ˆç½‘ç»œ
        F_fused = self.norm2(F_fused + self.ffn(F_fused))
        
        return F_fused
```

**ç‰©ç†æ„ä¹‰**ï¼š
- **Queryï¼ˆç‚¹äº‘ï¼‰**ï¼šæä¾›ç©ºé—´å‡ ä½•ç»“æ„ç´¢å¼•
- **Key/Valueï¼ˆå›¾åƒï¼‰**ï¼šæä¾›çº¹ç†å’Œé¢œè‰²ä¿¡æ¯
- **æ³¨æ„åŠ›æƒé‡**ï¼šè‡ªåŠ¨å­¦ä¹ å“ªäº›å›¾åƒç‰¹å¾å¯¹å½“å‰ç©ºé—´ä½ç½®æœ€é‡è¦

#### æ¨¡å—3: å¼‚å¸¸æ£€æµ‹å¤´

```python
class AnomalyDetectionHead(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv3d(input_dim, hidden_dim, 3, padding=1),
            nn.BatchNorm3d(hidden_dim),
            nn.ReLU(),
            nn.Conv3d(hidden_dim, hidden_dim // 2, 3, padding=1),
            nn.BatchNorm3d(hidden_dim // 2),
            nn.ReLU(),
            nn.Conv3d(hidden_dim // 2, 1, 1)  # è¾“å‡ºå¼‚å¸¸åˆ†æ•°
        )
    
    def forward(self, F_fused):
        anomaly_score = self.conv_layers(F_fused)
        return torch.sigmoid(anomaly_score)  # [B, 1, X, Y, Z]
```

---

## 4. æ•°æ®é›†è¯´æ˜

### 4.1 AnoVoxæ•°æ®é›†ç‰¹ç‚¹

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **è§„æ¨¡** | è¿„ä»Šæœ€å¤§çš„è‡ªåŠ¨é©¾é©¶å¼‚å¸¸æ£€æµ‹æ•°æ®é›† |
| **å¤šæ¨¡æ€** | RGBå›¾åƒ + LiDARç‚¹äº‘ + æ·±åº¦å›¾ + è¯­ä¹‰åˆ†å‰² |
| **æ ‡æ³¨ç²¾åº¦** | ä½“ç´ çº§ï¼ˆVoxel-levelï¼‰çœŸå€¼æ ‡æ³¨ |
| **å¼‚å¸¸ç±»å‹** | å†…å®¹å¼‚å¸¸ï¼ˆContent Anomalyï¼‰+ æ—¶åºå¼‚å¸¸ï¼ˆTemporal Anomalyï¼‰ |
| **è¯„ä¼°æŒ‡æ ‡** | AUROCã€AUPRCï¼ˆä¸å•æ¨¡æ€å…¬å¹³å¯¹æ¯”ï¼‰ |

### 4.2 æ•°æ®é›†ç»“æ„

```
AnoVox_Dynamic_Mono_Town07/
â”œâ”€â”€ Scenario_xxx/                      # åœºæ™¯æ–‡ä»¶å¤¹
â”‚   â”œâ”€â”€ RGB-CAM(...)_id/               # RGBå›¾åƒ
â”‚   â”‚   â”œâ”€â”€ RGB-CAM_xxx_5461.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ LIDAR(...)_id/                 # ç‚¹äº‘æ•°æ®
â”‚   â”‚   â”œâ”€â”€ LIDAR_xxx_5461.npy
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ VOXEL_GRID/                    # ä½“ç´ ç½‘æ ¼
â”‚   â”‚   â”œâ”€â”€ VOXEL_xxx_5461.npz
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ ANOMALY/                       # å¼‚å¸¸æ ‡æ³¨
â”‚   â”‚   â”œâ”€â”€ ANOMALY_xxx_5461.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ SEMANTIC-CAM(...)/             # è¯­ä¹‰åˆ†å‰²ï¼ˆå¯é€‰ï¼‰
â”‚   â”œâ”€â”€ DEPTH_CAM(...)/                # æ·±åº¦å›¾ï¼ˆå¯é€‰ï¼‰
â”‚   â””â”€â”€ sensor_setup.json              # ä¼ æ„Ÿå™¨é…ç½®
```

### 4.3 æ•°æ®åŠ è½½å™¨

**ä½ç½®**: `muvo/dataset/anovox_dataset.py`

**ä½¿ç”¨æ–¹æ³•**:
```python
from muvo.dataset.anovox_dataset import create_anovox_dataloader

# åˆ›å»ºè®­ç»ƒé›†åŠ è½½å™¨
train_loader = create_anovox_dataloader(
    data_root="/root/autodl-tmp/datasets/AnoVox/AnoVox_Dynamic_Mono_Town07",
    split='train',
    batch_size=4,
    num_workers=4,
    shuffle=True,
    load_voxel=True,
    load_anomaly_labels=True
)

# æ•°æ®æ ¼å¼
for batch in train_loader:
    images = batch['image']        # [B, 3, H, W]
    points = batch['points']       # [B, N, 4]
    voxels = batch['voxel']        # [B, X, Y, Z] (å¯é€‰)
    labels = batch['anomaly_label']  # å¼‚å¸¸æ ‡æ³¨ (å¯é€‰)
```

---

## 5. å®æ–½æ­¥éª¤

### Phase 1: æ•°æ®å‡†å¤‡ï¼ˆâœ… å·²å®Œæˆï¼‰

- [x] ä¸‹è½½AnoVoxæ•°æ®é›†
- [x] ç¼–å†™æ•°æ®åŠ è½½å™¨
- [x] éªŒè¯æ•°æ®åŠ è½½æ­£ç¡®æ€§

### Phase 2: æ¨¡å‹å®ç°ï¼ˆè¿›è¡Œä¸­ï¼‰

#### Step 1: å®ç°è·¨æ¨¡æ€æ³¨æ„åŠ›æ¨¡å—

**æ–‡ä»¶ä½ç½®**: `muvo/models/cross_modal_attention.py`

**å¾…å®ç°ç»„ä»¶**:
```python
# 1. 3Dä½ç½®ç¼–ç 
class PositionalEncoding3D(nn.Module):
    """ä¸ºä½“ç´ ç‰¹å¾æ·»åŠ 3Dç©ºé—´ä½ç½®ä¿¡æ¯"""
    
# 2. ç‰¹å¾ç©ºé—´å¯¹é½
class FeatureAligner(nn.Module):
    """å°†2Då›¾åƒç‰¹å¾æŠ•å½±åˆ°3Dä½“ç´ ç©ºé—´"""
    
# 3. è·¨æ¨¡æ€æ³¨æ„åŠ›
class CrossModalAttention(nn.Module):
    """æ ¸å¿ƒèåˆæ¨¡å—"""
```

#### Step 2: é›†æˆåˆ°æ£€æµ‹æ¡†æ¶

ä¿®æ”¹ `muvo/models/mile_anomaly.py`:

```python
class MileAnomalyDetector(nn.Module):
    def __init__(self, cfg):
        super().__init__()
        
        # 1. å†»ç»“çš„ç‰¹å¾æå–å™¨
        self.image_encoder = ResNet18(pretrained=True)
        self.image_encoder.requires_grad_(False)  # å†»ç»“
        
        self.lidar_encoder = Cylinder3D(pretrained=True)
        self.lidar_encoder.requires_grad_(False)  # å†»ç»“
        
        # 2. è·¨æ¨¡æ€æ³¨æ„åŠ›èåˆï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰
        self.fusion_module = CrossModalAttention(
            pc_dim=128,
            img_dim=512,
            hidden_dim=256,
            num_heads=8
        )
        
        # 3. å¼‚å¸¸æ£€æµ‹å¤´
        self.anomaly_head = AnomalyDetectionHead(
            input_dim=256,
            hidden_dim=128
        )
    
    def forward(self, batch):
        # æå–ç‰¹å¾
        with torch.no_grad():  # å†»ç»“éª¨å¹²
            F_img = self.image_encoder(batch['image'])
            F_pc = self.lidar_encoder(batch['points'])
        
        # è·¨æ¨¡æ€èåˆ
        F_fused = self.fusion_module(F_pc, F_img)
        
        # å¼‚å¸¸æ£€æµ‹
        anomaly_score = self.anomaly_head(F_fused)
        
        return anomaly_score
```

### Phase 3: è®­ç»ƒä¸è°ƒä¼˜

#### è®­ç»ƒè„šæœ¬

åˆ›å»º `train_anovox.py`:

```python
import pytorch_lightning as pl
from muvo.models.mile_anomaly import MileAnomalyDetector
from muvo.dataset.anovox_dataset import create_anovox_dataloader

# 1. æ•°æ®åŠ è½½
train_loader = create_anovox_dataloader(...)
val_loader = create_anovox_dataloader(...)

# 2. æ¨¡å‹åˆå§‹åŒ–
model = MileAnomalyDetector(cfg)

# 3. è®­ç»ƒé…ç½®
trainer = pl.Trainer(
    max_epochs=50,
    gpus=1,
    precision=16,  # æ··åˆç²¾åº¦è®­ç»ƒ
    callbacks=[
        pl.callbacks.ModelCheckpoint(monitor='val_auroc', mode='max'),
        pl.callbacks.EarlyStopping(monitor='val_auroc', patience=10)
    ]
)

# 4. å¼€å§‹è®­ç»ƒ
trainer.fit(model, train_loader, val_loader)
```

#### è¶…å‚æ•°é…ç½®

```yaml
# muvo/configs/anovox_cross_attention.yml

MODEL:
  ANOMALY_DETECTION:
    ENABLED: True
    FREEZE_BACKBONE: True  # å†»ç»“éª¨å¹²ç½‘ç»œ
    
    # è·¨æ¨¡æ€æ³¨æ„åŠ›é…ç½®
    PC_FEATURE_DIM: 128
    IMG_FEATURE_DIM: 512
    HIDDEN_DIM: 256
    NUM_HEADS: 8
    DROPOUT: 0.1
    
    # æ£€æµ‹å¤´é…ç½®
    HEAD_DIM: 128
    OUTPUT_DIM: 1

TRAIN:
  BATCH_SIZE: 4
  LEARNING_RATE: 1e-4
  WEIGHT_DECAY: 1e-5
  MAX_EPOCHS: 50
  
DATASET:
  NAME: 'AnoVox'
  DATAROOT: '/root/autodl-tmp/datasets/AnoVox/AnoVox_Dynamic_Mono_Town07'
```

### Phase 4: å®éªŒè¯„ä¼°

#### è¯„ä¼°æŒ‡æ ‡

```python
from sklearn.metrics import roc_auc_score, average_precision_score

def evaluate_anomaly_detection(predictions, ground_truth):
    """
    Args:
        predictions: [N, X, Y, Z] å¼‚å¸¸åˆ†æ•°
        ground_truth: [N, X, Y, Z] çœŸå€¼æ ‡ç­¾ï¼ˆ0/1ï¼‰
    """
    # å±•å¹³ä¸º1D
    preds_flat = predictions.reshape(-1)
    gt_flat = ground_truth.reshape(-1)
    
    # è®¡ç®—æŒ‡æ ‡
    auroc = roc_auc_score(gt_flat, preds_flat)
    auprc = average_precision_score(gt_flat, preds_flat)
    
    return {
        'AUROC': auroc,
        'AUPRC': auprc
    }
```

---

## 6. å®éªŒè®¾è®¡

### 6.1 åŸºçº¿å¯¹æ¯”å®éªŒ

| æ–¹æ³• | æè¿° | é¢„æœŸAUROC |
|------|------|-----------|
| **Single-Modal (Image)** | ä»…ä½¿ç”¨ResNet18 | ~0.75 |
| **Single-Modal (LiDAR)** | ä»…ä½¿ç”¨Cylinder3D | ~0.80 |
| **Baseline Fusion (AnoVox)** | ç®€å•ç‰¹å¾æ‹¼æ¥ | ~0.82 |
| **Ours (Cross-Attention)** | è·¨æ¨¡æ€æ³¨æ„åŠ›èåˆ | **~0.88** |

### 6.2 æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰

è¯æ˜æ¯ä¸ªç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼š

| å®éªŒé…ç½® | ç§»é™¤ç»„ä»¶ | é¢„æœŸå½±å“ |
|----------|----------|----------|
| **Full Model** | æ—  | æœ€ä½³æ€§èƒ½ï¼ˆBaselineï¼‰ |
| **No Positional Encoding** | 3Dä½ç½®ç¼–ç  | -2~3% AUROC |
| **No Attention** | æ³¨æ„åŠ›æœºåˆ¶ï¼ˆæ”¹ä¸ºç®€å•æ‹¼æ¥ï¼‰ | -5~7% AUROC |
| **No FFN** | å‰é¦ˆç½‘ç»œ | -1~2% AUROC |
| **Single-Head** | å¤šå¤´æœºåˆ¶ï¼ˆnum_heads=1ï¼‰ | -2~3% AUROC |

### 6.3 å¯è§†åŒ–åˆ†æ

ç”Ÿæˆä»¥ä¸‹å¯è§†åŒ–ç»“æœï¼š

1. **æ³¨æ„åŠ›æƒé‡å›¾**ï¼šå±•ç¤ºç‚¹äº‘Queryå¦‚ä½•æŸ¥è¯¢å›¾åƒç‰¹å¾
2. **å¼‚å¸¸æ£€æµ‹çƒ­åŠ›å›¾**ï¼šåœ¨3Dç©ºé—´ä¸­å¯è§†åŒ–å¼‚å¸¸åˆ†æ•°
3. **ROCæ›²çº¿**ï¼šå¯¹æ¯”ä¸åŒæ–¹æ³•çš„æ£€æµ‹æ€§èƒ½
4. **PRæ›²çº¿**ï¼šè¯„ä¼°ç²¾ç¡®ç‡-å¬å›ç‡æƒè¡¡

---

## 7. é¢„æœŸæˆæœ

### 7.1 æŠ€æœ¯æˆæœ

1. âœ… **ä¸€ä¸ªåˆ›æ–°çš„èåˆæ¨¡å‹**
   - åŸºäºè·¨æ¨¡æ€æ³¨æ„åŠ›çš„é“è·¯å¼‚å¸¸æ£€æµ‹æ¡†æ¶
   - ä»£ç å¼€æºï¼Œå¯å¤ç°

2. âœ… **æ˜¾è‘—çš„æ€§èƒ½æå‡**
   - ç›¸æ¯”AnoVoxåŸºçº¿ï¼ŒAUROCæå‡ **5~10%**
   - åœ¨å…¬å¼€æ’è¡Œæ¦œä¸Šå–å¾—ç«äº‰åŠ›ç»“æœ

3. âœ… **å……åˆ†çš„å®éªŒéªŒè¯**
   - å®Œæ•´çš„åŸºçº¿å¯¹æ¯”
   - ç³»ç»Ÿçš„æ¶ˆèå®éªŒ
   - ä¸°å¯Œçš„å¯è§†åŒ–åˆ†æ

### 7.2 å­¦æœ¯æˆæœ

1. **ç¡•å£«å­¦ä½è®ºæ–‡**
   - é¢˜ç›®ï¼šã€ŠåŸºäºè·¨æ¨¡æ€æ³¨æ„åŠ›çš„é“è·¯å¼‚å¸¸æ£€æµ‹æ–¹æ³•ç ”ç©¶ã€‹
   - ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘ä¸¥å¯†ï¼Œå®éªŒå……åˆ†

2. **ä¼šè®®è®ºæ–‡æŠ•ç¨¿**ï¼ˆå¯é€‰ï¼‰
   - ç›®æ ‡ä¼šè®®ï¼šCVPR, ICCV, ECCVï¼ˆè®¡ç®—æœºè§†è§‰é¡¶ä¼šï¼‰
   - æˆ–é¢†åŸŸä¼šè®®ï¼šIV, ITSCï¼ˆæ™ºèƒ½äº¤é€šï¼‰

### 7.3 æ—¶é—´è§„åˆ’

| é˜¶æ®µ | æ—¶é—´ | ä»»åŠ¡ |
|------|------|------|
| **Phase 1** | âœ… å·²å®Œæˆ | ç¯å¢ƒæ­å»ºã€æ•°æ®å‡†å¤‡ |
| **Phase 2** | Week 1-2 | æ¨¡å‹å®ç° |
| **Phase 3** | Week 3-4 | è®­ç»ƒè°ƒä¼˜ |
| **Phase 4** | Week 5-6 | å®éªŒè¯„ä¼°ã€æ¶ˆèç ”ç©¶ |
| **Phase 5** | Week 7-8 | è®ºæ–‡æ’°å†™ |

---

## 8. å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆå†»ç»“éª¨å¹²ç½‘ç»œï¼Ÿ

**ç­”**ï¼š
1. **é™ä½è®¡ç®—æˆæœ¬**ï¼šåªè®­ç»ƒèåˆæ¨¡å—ï¼Œæ˜¾å­˜éœ€æ±‚é™ä½70%+
2. **èšç„¦æ ¸å¿ƒåˆ›æ–°**ï¼šæˆ‘ä»¬çš„è´¡çŒ®æ˜¯èåˆæœºåˆ¶ï¼Œä¸æ˜¯ç‰¹å¾æå–å™¨
3. **åŠ é€Ÿæ”¶æ•›**ï¼šé¢„è®­ç»ƒæ¨¡å‹å·²ç»æä¾›äº†é«˜è´¨é‡ç‰¹å¾
4. **å…¬å¹³å¯¹æ¯”**ï¼šä¸åŸºçº¿ä½¿ç”¨ç›¸åŒçš„ç‰¹å¾ï¼Œå¯¹æ¯”æ›´å…¬å¹³

### Q2: å¦‚æœæ€§èƒ½æ²¡è¾¾åˆ°é¢„æœŸæ€ä¹ˆåŠï¼Ÿ

**ç­”**ï¼š
1. **è°ƒæ•´è¶…å‚æ•°**ï¼šå­¦ä¹ ç‡ã€hidden_dimã€num_heads
2. **æ”¹è¿›ä½ç½®ç¼–ç **ï¼šå°è¯•å¯å­¦ä¹ çš„ä½ç½®ç¼–ç 
3. **å¢å¼ºæ•°æ®**ï¼šæ•°æ®å¢å¼ºï¼ˆæ—‹è½¬ã€ç¿»è½¬ã€å™ªå£°ï¼‰
4. **å¤šå°ºåº¦èåˆ**ï¼šèåˆä¸åŒå±‚çº§çš„ç‰¹å¾
5. **é›†æˆå­¦ä¹ **ï¼šè®­ç»ƒå¤šä¸ªæ¨¡å‹å–å¹³å‡

### Q3: å’ŒMUVOåŸå§‹é¡¹ç›®çš„å…³ç³»ï¼Ÿ

**ç­”**ï¼š
- **MUVOåŸé¡¹ç›®**ï¼šç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶è§„åˆ’ï¼ˆimitation learningï¼‰
- **æˆ‘ä»¬çš„é¡¹ç›®**ï¼šé“è·¯å¼‚å¸¸æ£€æµ‹ï¼ˆanomaly detectionï¼‰
- **å…³ç³»**ï¼šæˆ‘ä»¬**å¤ç”¨**MUVOçš„ç‰¹å¾æå–å™¨ï¼Œä½†**åˆ›æ–°**èåˆæœºåˆ¶å’Œä»»åŠ¡ç›®æ ‡

---

## 9. å‚è€ƒèµ„æ–™

### æ•°æ®é›†ä¸åŸºå‡†
- [AnoVoxè®ºæ–‡](https://arxiv.org/abs/2403.17098) (CVPR 2024)
- [AnoVoxæ•°æ®é›†](https://zenodo.org/communities/anovox/)

### ç›¸å…³å·¥ä½œ
- [Cylinder3D](https://github.com/xinge008/Cylinder3D) - ç‚¹äº‘åˆ†å‰²SOTA
- [MUVO](https://github.com/Keyfingers/MUVO) - ç«¯åˆ°ç«¯é©¾é©¶æ¡†æ¶

### æŠ€æœ¯èƒŒæ™¯
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - TransformeråŸè®ºæ–‡
- [ViT: Vision Transformer](https://arxiv.org/abs/2010.11929) - è§†è§‰Transformer

---

## 10. ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³å¼€å§‹

```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•
cd /root/autodl-tmp/MUVO/MUVO

# 2. æµ‹è¯•æ•°æ®åŠ è½½
python muvo/dataset/anovox_dataset.py

# 3. å¼€å§‹å®ç°è·¨æ¨¡æ€æ³¨æ„åŠ›æ¨¡å—
# ç¼–è¾‘: muvo/models/cross_modal_attention.py

# 4. è¿è¡Œç¬¬ä¸€æ¬¡è®­ç»ƒ
python train_anovox.py --config muvo/configs/anovox_cross_attention.yml
```

### éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·æŸ¥é˜…ï¼š
- `README.md` - é¡¹ç›®æ€»ä½“è¯´æ˜
- `è¿è¡ŒæŒ‡å—.md` - MUVOåŸºç¡€ä½¿ç”¨æ–¹æ³•
- `ANOMALY_DETECTION_SUMMARY.md` - å¼‚å¸¸æ£€æµ‹æ¨¡å—æ€»ç»“

---

**ç¥ç ”ç©¶é¡ºåˆ©ï¼ğŸš€**

